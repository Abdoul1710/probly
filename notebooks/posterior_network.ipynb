{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b81968",
   "metadata": {},
   "source": [
    "# Posterior Network: Uncertainty Estimation without OOD Samples via Density-Based Pseudo-Counts\n",
    "\n",
    "Posterior Networks (PostNet) extend the idea of Evidential Deep Learning (EDL) by producing a full Dirichlet distribution over class probabilities for each input. However, instead of evidence being directly predicted by the neural network, PostNet does so by deriving evidence from class-conditional density estimates in a latent space. This assures that out-of-distribution (OOD) samples are not needed during training, as uncertainty increases for inputs that lie outside the learned density.\n",
    "\n",
    "In this notebook, we will:\n",
    "- Build a small encoder to map inputs into a latent space\n",
    "- Train a separate normalizing flow per class to model the class-conditional densities\n",
    "- Convert densities into evidence (pseudo-counts)\n",
    "- Construct Dirichlet posteriors and evaluate uncertainty\n",
    "- Compare uncertainty on in-distribution (ID) and OOD samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187fd6fa",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d22d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nadzuken/probly/.venv/bin/python: No module named uv\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "%uv pip install nflows\n",
    "from nflows.distributions.normal import StandardNormal\n",
    "from nflows.flows import Flow\n",
    "from nflows.nn.nets import MLP\n",
    "from nflows.transforms import AffineCouplingTransform, CompositeTransform, ReversePermutation\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d91721",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Posterior Networks require:\n",
    "- an in-distribution (ID) dataset used for training and standard evaluation\n",
    "- an out-of-distribution dataset used only for testing epistemic uncertainty\n",
    "\n",
    "Here, we use **MNIST** as the ID dataset and **FashionMNIST** as the OOD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93bbf28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST loaded (ID).\n"
     ]
    }
   ],
   "source": [
    "transform = T.Compose([T.ToTensor()])\n",
    "\n",
    "# In-distribution data\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root=\"~/datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root=\"~/datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "train_loader    = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_loader     = DataLoader(test_data, batch_size=256, shuffle=False)\n",
    "\n",
    "print (\"MNIST loaded (ID).\")\n",
    "\n",
    "# Out-of-distribution data\n",
    "\n",
    "ood_data = torchvision.datasets.FashionMNIST(\n",
    "    root=\"~/datasets\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "ood_loader = DataLoader(ood_data, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c437fd8",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Posterior Networks are composed of:\n",
    "1. **Encoder**: maps each image to a low-dimensional latent vector.\n",
    "2. **Class-conditional normalizing flows**: one flow per class, modeling the density P(z|c) in latent space. These densities provide the evidence used to construct the Dirichlet distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4886e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder: maps images (x) -> latent (z)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=2) -> None:  # noqa: ANN001\n",
    "        \"\"\"Initializes an instance of the Encoder class.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(), # turns a 28x28 image into a vector of size 784\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim), # final output = latent vector z\n",
    "        )\n",
    "\n",
    "    def forward(self, x) -> None:  # noqa: ANN001, D102\n",
    "        return self.net(x)\n",
    "\n",
    "# Normalizing Flow for P(z | c)\n",
    "\n",
    "class ContextIgnoreNet(nn.Module):\n",
    "    def __init__(self, in_features, out_features) -> None:  # noqa: ANN001, D107\n",
    "        super().__init__()\n",
    "        self.net = MLP(\n",
    "            in_shape=(in_features,),\n",
    "            out_shape=(out_features,),\n",
    "            hidden_sizes=[32, 32],\n",
    "        )\n",
    "\n",
    "    def forward(self, x, context=None) -> None:  # noqa: ANN001, ARG002, D102\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "\n",
    "def make_flow(latent_dim) -> None:  # noqa: ANN001\n",
    "\n",
    "    # Required function that returns a transform network\n",
    "    def transform_net_create_fn(in_features, out_features) -> None:  # noqa: ANN001\n",
    "        return ContextIgnoreNet(in_features, out_features)\n",
    "\n",
    "    base_dist = StandardNormal([latent_dim])\n",
    "\n",
    "    transform = CompositeTransform([\n",
    "        AffineCouplingTransform(\n",
    "            mask=[0, 1],\n",
    "            transform_net_create_fn=transform_net_create_fn,\n",
    "        ),\n",
    "        ReversePermutation(features=latent_dim),\n",
    "        AffineCouplingTransform(\n",
    "            mask=[1, 0],\n",
    "            transform_net_create_fn=transform_net_create_fn,\n",
    "        ),\n",
    "    ])\n",
    "\n",
    "    return Flow(transform, base_dist)\n",
    "\n",
    "latent_dim = 2\n",
    "encoder = Encoder(latent_dim).to(device)\n",
    "flows = nn.ModuleList([make_flow(latent_dim).to(device) for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45df54f",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "937e8a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_postnet(encoder, flows, train_loader, epochs=5, lr=1e-3, device=\"cuda\") -> None:  # noqa: ANN001\n",
    "    encoder.train()\n",
    "    flows.train()\n",
    "\n",
    "    # Combine encoder & flows paramters so one optimizer updates all of them\n",
    "    params = list(encoder.parameters()) + list(flows.parameters())\n",
    "    optimizer = optim.Adam(params, lr=lr)\n",
    "\n",
    "    class_counts = torch.zeros(10).to(device)\n",
    "    for _, y in train_loader:\n",
    "        for c in range(10):\n",
    "            class_counts[c] += (y == c).sum()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)  # noqa: PLW2901\n",
    "\n",
    "            # Encode image -> latent vector\n",
    "            z = encoder(x)\n",
    "\n",
    "            # Compute density P(z|c) for all classes\n",
    "            densities = torch.stack(\n",
    "                [flow.log_prob(z).exp() for flow in flows], dim=1,\n",
    "            )\n",
    "\n",
    "            # Compute pseudo-counts beta\n",
    "            beta = densities * class_counts\n",
    "\n",
    "            # Dirichlet parameters alpha\n",
    "            alpha = beta + 1.0\n",
    "            alpha0 = alpha.sum(dim=1, keepdim=True)\n",
    "\n",
    "            # Expected cross-entropy term\n",
    "            digamma = torch.digamma\n",
    "            expected_ce = digamma(alpha0) - digamma(alpha[range(len(y)), y])\n",
    "\n",
    "            # Entropy of Dirichlet\n",
    "            entropy = -(alpha * (digamma(alpha) - digamma(alpha0))).sum(dim=1)\n",
    "\n",
    "            # Total loss\n",
    "            loss = (expected_ce - entropy).mean()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd79bb6d",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2792a911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "Epoch 1/1 - Loss: -20575.7173\n",
      "\n",
      "Epoch 2/5\n",
      "Epoch 1/1 - Loss: -22023.9898\n",
      "\n",
      "Epoch 3/5\n",
      "Epoch 1/1 - Loss: -22041.8797\n",
      "\n",
      "Epoch 4/5\n",
      "Epoch 1/1 - Loss: -22042.5871\n",
      "\n",
      "Epoch 5/5\n",
      "Epoch 1/1 - Loss: -22042.8257\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    train_postnet(\n",
    "        encoder, flows, train_loader,\n",
    "        epochs=1,\n",
    "        lr=1e-3,\n",
    "        device=device,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
