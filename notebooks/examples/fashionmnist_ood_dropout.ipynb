{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import probly\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ad45423e645d25d2",
   "metadata": {},
   "source": "### Load data and create neural network"
  },
  {
   "cell_type": "code",
   "id": "c46a7ac99306c3d2",
   "metadata": {},
   "source": [
    "transforms = T.Compose([T.ToTensor(), torch.flatten])\n",
    "train = torchvision.datasets.FashionMNIST(root='~/datasets/', train=True, download=True, transform=transforms)\n",
    "test = torchvision.datasets.FashionMNIST(root='~/datasets/', train=False, download=True, transform=transforms)\n",
    "train_loader = DataLoader(train, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test, batch_size=256, shuffle=False)\n",
    "\n",
    "ood = torchvision.datasets.MNIST(root='~/datasets/', train=False, download=True, transform=transforms)\n",
    "ood_loader = DataLoader(ood, batch_size=256, shuffle=False)\n",
    "\n",
    "# small fully connected neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.fc1(x))\n",
    "        x = self.act(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2bdf6ad4b8416b15",
   "metadata": {},
   "source": "### Make neural network a dropout model using probly"
  },
  {
   "cell_type": "code",
   "id": "e846c75162008235",
   "metadata": {},
   "source": [
    "model = probly.models.dropout.Dropout(net)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "13393ea634149065",
   "metadata": {},
   "source": "### Train model as usual"
  },
  {
   "cell_type": "code",
   "id": "4159c8c1b155349c",
   "metadata": {},
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for _ in tqdm(range(10)):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, 1).squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "# compute accuracy on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "for inputs, targets in test_loader:\n",
    "    outputs = model(inputs, 100).mean(axis=1)\n",
    "    outputs = outputs.argmax(axis=1)\n",
    "    correct += (outputs == targets).sum().item()\n",
    "    total += targets.size(0)\n",
    "print(f\"Accuracy: {correct / total}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9f498d9c316bedc5",
   "metadata": {},
   "source": "### Compute epistemic uncertainty for in-distribution (MNIST) and out-of-distribution (FashionMNIST) data using probly"
  },
  {
   "cell_type": "code",
   "id": "2cb4100584576a06",
   "metadata": {},
   "source": [
    "@torch.no_grad()\n",
    "def torch_get_outputs(model, loader):\n",
    "    outputs = torch.empty(0)\n",
    "    targets = torch.empty(0)\n",
    "    for inputs, targets_ in loader:\n",
    "        outputs_ = model(inputs, 100)\n",
    "        outputs = torch.cat((outputs, outputs_), dim=0)\n",
    "        targets = torch.cat((targets, targets_), dim=0)\n",
    "    return outputs, targets\n",
    "\n",
    "# get all outputs\n",
    "outputs_id, _ = torch_get_outputs(model, test_loader)\n",
    "outputs_ood, _ = torch_get_outputs(model, ood_loader)\n",
    "outputs_id = F.softmax(outputs_id, dim=2).numpy()\n",
    "outputs_ood = F.softmax(outputs_ood, dim=2).numpy()\n",
    "\n",
    "# compute uncertainties\n",
    "uncertainty_id = probly.measures.distributions.epistemic_uncertainty_entropy(outputs_id)\n",
    "uncertainty_ood = probly.measures.distributions.epistemic_uncertainty_entropy(outputs_ood)\n",
    "\n",
    "# plot them in same histogram\n",
    "plt.hist(uncertainty_id, bins=50, alpha=0.5, label='In-distribution')\n",
    "plt.hist(uncertainty_ood, bins=50, alpha=0.5, label='Out-of-distribution')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8ca2d34292477c67",
   "metadata": {},
   "source": "### Do Out-of-Distribution task using probly"
  },
  {
   "cell_type": "code",
   "id": "7dcf980787a9f204",
   "metadata": {},
   "source": [
    "auroc = probly.tasks.out_of_distribution_detection(uncertainty_id, uncertainty_ood)\n",
    "print(f'AUROC with FashionMNIST as iD and MNIST as OoD: {auroc:.3f}')"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
