{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf91a2d-9a1d-41ab-aa15-d5cfff492221",
   "metadata": {},
   "source": [
    "## Deep Evidential Regression (Amini et al., 2020) - Summary\n",
    "\n",
    "### 1.  Introduction: Why do we need uncertainty estimation in regression?\n",
    "\n",
    "Neural Networks are increasingly being used in places where mistakes can be dangerous or expensive, such as autonomous driving or medical tasks. \n",
    "\n",
    "In these situations, it’s not enough to only receive a prediction. In order to minimize mistakes as much as possible, the model should not only output a prediction, but also say how certain it is about said prediction. #\n",
    "\n",
    "Having reliable uncertainty estimates helps prevent wrong decisions, detect unusual data, and improve the safety of machine learning systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a25da-c1d1-4343-8b55-f50ef352cb7a",
   "metadata": {},
   "source": [
    "### 2. What is Deep Evidential Regression? \n",
    "\n",
    "Deep Evidential Regression is a method where a neural network predicts the parameters of a Normal-Inverse-Gamma distribution instead of predicting a single output. \n",
    "\n",
    "This higher-order distribution represents “evidence” for the prediction and allows the model to estimate both aleatoric and epistemic uncertainty in one forward pass, without sampling or ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15bf096-6df2-4633-a879-8e3fdcc205e1",
   "metadata": {},
   "source": [
    "### 3. Two types of uncertainties in regression models \n",
    "\n",
    "**Aleatoric Uncertainty:** noise in the data; it is caused by randomness or measurement noise that even a perfect model can’t eliminate. An example for that would be a noisy sensor reading distance. \n",
    "\n",
    "**Epistemic uncertainty:** the model simply doesn’t know enough; it is caused by a lack of knowledge, which decreases with more data. This uncertainty is high when the model sees something unfamiliar or out-of-distribution. An example would be training the model on indoor-only images and then suddenly showing it a snowy mountain. \n",
    "\n",
    "These two uncertainties behave differently and matter in different ways, so a good system should be able to estimate both. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f268f9a5-f0cf-48de-8a64-8fdfe703c63e",
   "metadata": {},
   "source": [
    "### 4. Proposal of Amini et al. \n",
    "\n",
    "The main idea of the paper is to let a neural network predict not only a single output value, but the parameters of a Normal-Inverse-Gamma (NIG) distribution.\n",
    "This distribution is a higher-order distribution that represents uncertainty about the parameters of a Gaussian likelihood (its mean and variance). By learning this distribution, the model can estimate both aleatoric and epistemic uncertainty in a principled way.\n",
    "\n",
    "For each regression target, the network outputs four values:\n",
    "\n",
    "- **γ**: predicted mean\n",
    "- **υ**: strength of belief about the mean\n",
    "- **α**: evidence related to the variance\n",
    "- **β**: scale parameter for the variance\n",
    "\n",
    "Using these parameters, the model can compute:\n",
    "\n",
    "- the final prediction\n",
    "- the aleatoric uncertainty\n",
    "- the epistemic uncertainty\n",
    "\n",
    "The key idea is that the NIG distribution captures uncertainty about the likelihood parameters themselves, not just about the data.\n",
    "This allows the model to express how confident it is about its own prediction without using sampling, dropout, or model ensembles.\n",
    "\n",
    "Because the model learns how much evidence it has for its predictions, it can increase uncertainty when it makes mistakes or when it sees out-of-distribution data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff2b3dd-4229-4b6f-a324-a2d2ddc8ab10",
   "metadata": {},
   "source": [
    "### 5. Loss Functions\n",
    "\n",
    "As explained earlier, in Deep Evidential Regression, the neural network not only outputs a single prediction, but also the parameters of a Normal-Inverse-Gamma distribution. Because of this, the loss function needs to do two things at the same time: make the prediction fit the data + control how much evidence or uncertainty the model produces. \n",
    "\n",
    "Because the model outputs a Normal-Inverse-Gamma (NIG) distribution, the resulting likelihood over the target becomes a Student-t distribution. The Student-t distribution is similar to a Gaussian but has heavier tails, which makes it better at handling uncertainty and outliers. This is why the loss function uses the Student-t Negative Log-Likelihood (NLL).\n",
    "\n",
    "The paper combines two different loss components into one: \n",
    "\n",
    "**1. Student-t Negative Log-Likelihood (NLL)**  \n",
    "\n",
    "This measures how well the predicted distribution matches the true target value.\n",
    "Because the NIG distribution induces a Student-t likelihood, this term naturally models the data noise and is responsible for learning aleatoric uncertainty.\n",
    "\n",
    "**2. Evidence Regularizer**  \n",
    "This penalizes the model when it assigns a large amount of evidence (high confidence) to a prediction that is far from the true value.\n",
    "It encourages the network to reduce evidence and increase epistemic uncertainty whenever it encounters unfamiliar or difficult inputs.\n",
    "\n",
    "The total loss is simply:\n",
    "The final loss combines both parts:\n",
    "\n",
    "$$\n",
    "L = L_{\\text{NLL}} + \\lambda \\cdot L_R\n",
    "$$\n",
    "\n",
    "where the regularizer is:\n",
    "\n",
    "$$\n",
    "L_R = |y - \\gamma| \\cdot (2\\upsilon + \\alpha)\n",
    "$$\n",
    "\n",
    "This loss encourages the model to make accurate predictions while also expressing meaningful uncertainty.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6082167e-1904-4b5c-ba9e-a1e029571739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc82423-b3d3-42d3-a325-851a67b2585c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evidential Regression Loss (Amini et al., 2020)\n",
    "# Implements the Student-t NLL + Evidence Regularizer\n",
    "\n",
    "\n",
    "def evidential_loss(y, gamma, v, alpha, beta, lam=1.0):\n",
    "    \"\"\"Implements the loss from Deep Evidential Regression:\n",
    "    L = LNLL + λ * LR\n",
    "\n",
    "    Parameters:\n",
    "    y      : ground truth values\n",
    "    gamma  : predicted mean\n",
    "    v      : evidence for mean\n",
    "    alpha  : evidence for variance (> 1)\n",
    "    beta   : scale parameter (> 0)\n",
    "    lam    : regularization weight λ\n",
    "    \"\"\"\n",
    "    # 1. Student-t Negative Log Likelihood (LNLL) --> Equation (8) on the paper\n",
    "    two_bv = 2 * beta * (1 + v)\n",
    "\n",
    "    LNLL = (\n",
    "        0.5 * torch.log(torch.pi / v)\n",
    "        - alpha * torch.log(two_bv)\n",
    "        + (alpha + 0.5) * torch.log(v * (y - gamma) ** 2 + two_bv)\n",
    "        + torch.lgamma(alpha)\n",
    "        - torch.lgamma(alpha + 0.5)\n",
    "    )\n",
    "\n",
    "    # 2. Evidence Regularizer LR\n",
    "    # LR = |y - γ| * (2v + α) --> Equation (9) on the paper\n",
    "\n",
    "    evidence = 2 * v + alpha\n",
    "    LR = torch.abs(y - gamma) * evidence\n",
    "\n",
    "    # 3. Combined Loss (the one we need)\n",
    "\n",
    "    loss = LNLL + lam * LR\n",
    "\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11e4a3-9bbd-4cea-8977-5884c7d79942",
   "metadata": {},
   "source": [
    "### 6. Comparison with Sensoy et al. (2018)\n",
    "\n",
    "The Sensoy et al. paper introduces evidential learning for classification using a Dirichlet distribution and a KL-based evidence regularized. Amini et al. extends the evidential idea to regression, using Normal-Inverse-Gamma distribution and a new evidence penalty to capture both aleatoric and epistemic uncertainty. \n",
    "\n",
    "Together, these two papers form the foundation of modern evidential deep learning for both classification and regression. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416682be-b66c-4017-ac8a-da151d59ba09",
   "metadata": {},
   "source": [
    "### 7. Implementation Example (PyTorch)\n",
    "\n",
    "Below is a minimal PyTorch example showing how the Deep Evidential Regression loss can be used to train a simple model on a toy regression dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2535171-130c-4fcc-aae8-d894abc11f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny toy dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.linspace(-3, 3, 200).unsqueeze(1)\n",
    "y = x**3 + 0.3 * torch.randn_like(x)\n",
    "\n",
    "\n",
    "# minimal model\n",
    "class EvidentialNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(1, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        gamma = out[:, 0:1]\n",
    "        v = F.softplus(out[:, 1:2])\n",
    "        alpha = F.softplus(out[:, 2:3]) + 1\n",
    "        beta = F.softplus(out[:, 3:4])\n",
    "        return gamma, v, alpha, beta\n",
    "\n",
    "\n",
    "model = EvidentialNet()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# short training loop\n",
    "for _ in range(1500):\n",
    "    opt.zero_grad()\n",
    "    gamma, v, alpha, beta = model(x)\n",
    "    loss = evidential_loss(y, gamma, v, alpha, beta, lam=1e-2)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "# visualize result\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.plot(x, model(x)[0].detach(), color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a025b9-1847-4a36-b013-2afb34129fdc",
   "metadata": {},
   "source": [
    "### 8. Project Insights \n",
    "\n",
    "Amini et al. (2020) provide the theoretical and practical foundation for evidential regression in probly. Their NIG-based uncertainty model, loss function, and evidence regularizer are exactly what our project needs to use to implement fast, sampling-free uncertainty estimation for continuous outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb6e14d-4026-409f-81ff-b43964fc2fba",
   "metadata": {},
   "source": [
    "### 9. Summary\n",
    "\n",
    "Deep Evidential Regression gives neural networks a way to predict both a value and how certain they are about it. By predicting the parameters of a Normal-Inverse-Gamma distribution, the model learns aleatoric and epistemic uncertainty in a single forward pass. The combination of the Student-T likelihood and the evidence regularizer ensures that the model becomes confident only when it should. Overall, this method provides a simple and efficient way to add uncertainty estimation to regression models without relying on sampling or ensembles."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
